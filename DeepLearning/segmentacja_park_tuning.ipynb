{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Łukasz Folwarczyk**\n",
    "\n",
    "*\"Badanie i implementacja algorytmów detekcji drogi przy wykorzystaniu cyfrowego przetwarzania obrazów.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentacja park tuning\n",
    "\n",
    "\n",
    "Notatnik implementujący architekturę głębokiej sieci neuronowej, wykorzystanej do problemu segmentacji obrazów przedstawiających widoki dróg parkowych. Działanie modułu opisane zostało w paragrafie 5.1.1 - przypadek III."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy\n",
    "import os, sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import TerminateOnNaN\n",
    "sys.path.append('../../../Tools/cropping2d')\n",
    "from croppingLike2D import CroppingLike2D\n",
    "import math\n",
    "from random import shuffle\n",
    "from math import ceil\n",
    "from random import randint\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "import scipy.misc\n",
    "import gc\n",
    "import datetime\n",
    "import h5py\n",
    "from IPython.display import clear_output\n",
    "\n",
    "timefunc = time.time\n",
    "assert K.backend() == 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(hdf5_filename, \n",
    "                    dataset_img, \n",
    "                    dataset_label, \n",
    "                    one_hot, \n",
    "                    batch_size, \n",
    "                    shuffle_batch = True):\n",
    "    \"\"\" \n",
    "    Opis:\n",
    "    ---\n",
    "    Funkcja pełniąca rolę generatora próbek (mini-paczek) uczących oraz walidacyjnych.\n",
    "    Wykorzystywana w procesie uczenia głębokiej sieci neuronowej.\n",
    "    \n",
    "    Argumenty:\n",
    "    ---\n",
    "        hdf5_filename (string):   nazwa pliku zawierającego zbiór danych\n",
    "        \n",
    "        dataset_img (string):     nazwa zbioru pliku hdf5, \n",
    "                                  w którym zapisane sa obrazy\n",
    "        \n",
    "        dataset_label (string):   nazwa zbioru pliku hdf5, \n",
    "                                  w którym zapisane sa etykiety\n",
    "        \n",
    "        one_hot (boolean):        kodowanie gorąco-jedynkowe\n",
    "                                                                  \n",
    "        batch_size (int):         ilość generowanych próbek (wielkość mini-paczki)\n",
    "        \n",
    "        shuffle_batch (int):      losowe próbki ze zbioru\n",
    "    \n",
    "    Return:\n",
    "    ---\n",
    "        generator (truple):       mini-paczka zawierająca obrazy oraz ich etykiety\n",
    "    \"\"\"\n",
    "    # otwarcie pliku hdf5\n",
    "    with h5py.File(hdf5_filename) as hdf_file_read:                                 \n",
    "        # wyznaczenie wielkosci zbioru zapisanego w pliku\n",
    "        dataset_len = hdf_file_read[dataset_img].shape[0]                          \n",
    "        # liczba mini-paczek możliwych do wygenerowania z danego zbioru\n",
    "        number_of_batches = int(ceil(float(dataset_len) / batch_size)) #ilosc batchy = foty / pojemnosc_batcha\n",
    "        batches_list = list(range(number_of_batches))\n",
    "        # losowość min-paczki\n",
    "        if shuffle_batch:\n",
    "            shuffle(batches_list)\n",
    "        i = 0\n",
    "        while True:\n",
    "            # wyznaczenie indeksu początkowego i końcowego obrazów oraz etykiet,\n",
    "            # które zostaną odczytane z pliku i przekazane w postaci mini-paczki\n",
    "            first_image_in_batch_index = batches_list[i] * batch_size\n",
    "            last_image_in_batch_index = min([(batches_list[i] + 1) * batch_size, dataset_len])\n",
    "            # odczytanie z pliku obrazów i etykiet o wyznaczonych indeksach\n",
    "            reconstructed_img = (hdf_file_read[dataset_img][first_image_in_batch_index:last_image_in_batch_index, ...])\n",
    "            reconstructed_label = (hdf_file_read[dataset_label][first_image_in_batch_index:last_image_in_batch_index, ...])\n",
    "            # przejście przez cały zbiór obrazów/etykiet zapisany w pliku (pokazanie wszystkich próbek)\n",
    "            # jeśli w min-paczkach pokazano wszystkie próbki to rozpoczni od nowa, \n",
    "            # jesli wybrano shuffle_batch to w każdym nowym cyklu próbki są generowane w losowej kolejności\n",
    "            if i < (number_of_batches - 1):\n",
    "                i += 1\n",
    "            else:\n",
    "                i = 0\n",
    "                if shuffle_batch:\n",
    "                    shuffle(batches_list)\n",
    "            # generowanie mini-paczek\n",
    "            yield reconstructed_img.astype(np.float32), reconstructed_label.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator_test(hdf5_filename, \n",
    "                         dataset_img, \n",
    "                         batch_size, \n",
    "                         shuffle_batch = True):\n",
    "    \"\"\" \n",
    "    Opis:\n",
    "    ---\n",
    "    Funkcja pełniąca rolę generatora próbek (mini-paczek) testowych (nie zawierają etykiet).\n",
    "    Wykorzystywana w procesie testowania głębokiej sieci neuronowej.\n",
    "    \n",
    "    Argumenty:\n",
    "    ---\n",
    "        hdf5_filename (string):   nazwa pliku zawierającego zbiór danych\n",
    "        \n",
    "        dataset_img (string):     nazwa zbioru pliku hdf5, \n",
    "                                  w którym zapisane sa obrazy\n",
    "                                                                  \n",
    "        batch_size (int):         ilość generowanych próbek (wielkość mini-paczki)\n",
    "        \n",
    "        shuffle_batch (int):      losowe próbki ze zbioru\n",
    "    \n",
    "    Return:\n",
    "    ---\n",
    "        generator (truple):       mini-paczka zawierająca obrazy\n",
    "    \"\"\"\n",
    "    # otwarcie pliku hdf5\n",
    "    with h5py.File(hdf5_filename) as hdf_file_read:\n",
    "        # wyznaczenie wielkosci zbioru zapisanego w pliku\n",
    "        dataset_len = hdf_file_read[dataset_img].shape[0]\n",
    "        # liczba mini-paczek możliwych do wygenerowania z danego zbioru\n",
    "        number_of_batches = int(ceil(float(dataset_len) / batch_size))\n",
    "        batches_list = list(range(number_of_batches))\n",
    "        # losowość min-paczki\n",
    "        if shuffle_batch:\n",
    "            shuffle(batches_list)\n",
    "        i = 0\n",
    "        while True:\n",
    "            # wyznaczenie indeksu początkowego i końcowego obrazów,\n",
    "            # które zostaną odczytane z pliku i przekazane w postaci mini-paczki\n",
    "            first_image_in_batch_index = batches_list[i] * batch_size  # index of the first image in this batch\n",
    "            last_image_in_batch_index = min([(batches_list[i] + 1) * batch_size, dataset_len])\n",
    "            # odczytanie z pliku obrazów o wyznaczonych indeksach\n",
    "            reconstructed_img = (hdf_file_read[dataset_img][first_image_in_batch_index:last_image_in_batch_index, ...])\n",
    "            # przejście przez cały zbiór obrazów/etykiet zapisany w pliku (pokazanie wszystkich próbek)\n",
    "            # jeśli w min-paczkach pokazano wszystkie próbki to rozpoczni od nowa, \n",
    "            # jesli wybrano shuffle_batch to w każdym nowym cyklu próbki są generowane w losowej kolejności\n",
    "            if i < (number_of_batches - 1):\n",
    "                i += 1\n",
    "            else:\n",
    "                i = 0\n",
    "                if shuffle_batch:\n",
    "                    shuffle(batches_list)\n",
    "            # generowanie mini-paczek\n",
    "            yield reconstructed_img.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, image_type):\n",
    "    \"\"\" \n",
    "    Opis:\n",
    "    ---\n",
    "    Funkcja normalizująca obraz.\n",
    "    \n",
    "    Argumenty:\n",
    "    ---\n",
    "        image (numpy.ndarray):    obraz wejściowy\n",
    "        \n",
    "        image_type (numpy.dtype): typ obrazu wejściowego\n",
    "    \n",
    "    Return:\n",
    "    ---\n",
    "        image (numpy.ndarray):    obraz znormalizowany\n",
    "    \"\"\"\n",
    "    mean = image.mean()\n",
    "    image = image - mean\n",
    "    image /= (image.std() + 1e-5)\n",
    "    image *= 0.1\n",
    "    image += 0.5\n",
    "    image = np.clip(image, 0, 1)\n",
    "    image *= 255\n",
    "    image = image.astype(image_type)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_layer_trainable(model):\n",
    "    \"\"\" \n",
    "    Opis:\n",
    "    ---\n",
    "    Funkcja wyświetla nazwy wszystkich warstw obecnych w modelu i\n",
    "    informacje o tym, czy podlegają one procesowi uczenia.\n",
    "    \n",
    "    Argumenty:\n",
    "    ---\n",
    "        model (keras.engine.training.Model):   nazwa pliku zawierającego zbiór danych\n",
    "    \n",
    "    Return:\n",
    "    ---\n",
    "        None\n",
    "    \"\"\"\n",
    "    for layer in model.layers:\n",
    "        print(\"{0}: \\t{1}\".format(layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img_batch(hdf5_filename, \n",
    "                      dataset_img, \n",
    "                      dataset_label, \n",
    "                      one_hot, \n",
    "                      batch_size, \n",
    "                      class_index):  \n",
    "    \"\"\" \n",
    "    Opis:\n",
    "    ---\n",
    "    Funkcja wyświetla przykładowe obrazy oraz ich etykiety, \n",
    "    zapisane w pliku z rozszerzeniem hdf5.\n",
    "    \n",
    "    Argumenty:\n",
    "    ---\n",
    "        hdf5_filename (string):   nazwa pliku wynikowego\n",
    "        \n",
    "        dataset_img (string):     nazwa zbioru pliku hdf5, \n",
    "                                  w którym zapisane sa obrazy\n",
    "        \n",
    "        dataset_label (string):   nazwa zbioru pliku hdf5, \n",
    "                                  w którym zapisane sa etykiety\n",
    "        \n",
    "        one_hot (boolean):        kodowanie gorąco-jedynkowe\n",
    "                                                                  \n",
    "        batch_size (int):         ilosć wyświetlonych próbek\n",
    "        \n",
    "        class_index (int):        numer klasy wyróżnionej na zdjęciu\n",
    "    \n",
    "    Return:\n",
    "    ---\n",
    "        None\n",
    "    \"\"\"\n",
    "    with h5py.File(hdf5_filename) as hdf_file_read:                  # otwarcie pliku hdf5\n",
    "        height = hdf_file_read[\"height\"][0, ...]                     # odczytanie wysokosci obrazów/etykiet\n",
    "        width = hdf_file_read[\"width\"][0, ...]                       # odczytanie szerokoci obrazów/etykiet\n",
    "        cls =  hdf_file_read[\"classes\"][0, ...]                      # odczytanie ilości klas w etykietach\n",
    "        dataset_len = hdf_file_read[dataset_img].shape[0]            # odczytanie ilości par obraz/etykieta\n",
    "        \n",
    "        # wyświetlenie par obraz/etykieta (ilość zależna od parametru batch_size)\n",
    "        for i in range(batch_size):\n",
    "            # zostaje wyświetlona losowa para\n",
    "            rand = randint(0, dataset_len)\n",
    "            \n",
    "            # odtworzenie obrazu / etykiety\n",
    "            reconstructed_img = (hdf_file_read[dataset_img][rand:min(rand + 1,dataset_len), ...])\n",
    "            reconstructed_img = reconstructed_img[0,:,:,:]\n",
    "            img_shape = reconstructed_img.shape\n",
    "            reconstructed_label = (hdf_file_read[dataset_label][rand:min(rand + 1,dataset_len), ...])\n",
    "            \n",
    "            # przetworzenie etykiety w zalezności od kodowania\n",
    "            if one_hot:\n",
    "                reconstructed_label = reconstructed_label[0,:,:]\n",
    "                label_shape = reconstructed_label.shape\n",
    "                reconstructed_label = reconstructed_label.reshape(height,width,cls)\n",
    "            else:\n",
    "                reconstructed_label = reconstructed_label[0,:,:,:]\n",
    "                label_shape = reconstructed_label.shape\n",
    "             \n",
    "            # wyświetlenie pary obraz/etykieta\n",
    "            fig = plt.figure()\n",
    "            fig.add_subplot(1, 2, 1)\n",
    "            plt.imshow(reconstructed_img)\n",
    "            fig.add_subplot(1, 2, 2)\n",
    "            plt.imshow(reconstructed_label[:,:,class_index])\n",
    "    print(\"---------------------------\".format(dataset_len))\n",
    "    print(\"Ilość obrazów w zbiorze: {}\".format(dataset_len))\n",
    "    print(\"Kształt obrazów: {}\".format(img_shape))\n",
    "    print(\"Kształt etykiet: {}\".format(label_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_examples_in_dataset(hdf5_filename,\n",
    "                                  dataset_img,\n",
    "                                  dataset_label):\n",
    "    \"\"\" \n",
    "    Opis:\n",
    "    ---\n",
    "    Funkcja wyznacza ilośc próbek w zbiorze danych (zapisanym w pliku hdf5).\n",
    "    \n",
    "    Argumenty:\n",
    "    ---\n",
    "        hdf5_filename (string):   nazwa pliku zawierającego zbiór danych\n",
    "        \n",
    "        dataset_img (string):     nazwa zbioru pliku hdf5, \n",
    "                                  w którym zapisane sa obrazy\n",
    "        \n",
    "        dataset_label (string):   nazwa zbioru pliku hdf5, \n",
    "                                  w którym zapisane sa etykiety\n",
    "    \n",
    "    Return:\n",
    "    ---\n",
    "        None\n",
    "    \"\"\"\n",
    "    with h5py.File(hdf5_filename) as hdf_file_read:                  # otwarcie pliku hdf5\n",
    "        dataset_len_img = hdf_file_read[dataset_img].shape[0]        # odczytanie ilości obrazów w zbiorze\n",
    "        dataset_len_labels = hdf_file_read[dataset_label].shape[0]   # odczytanie ilości etykiet w zbiorze\n",
    "        \n",
    "        # sprawdzenie czy ilość obrazów i etykiet jest zgodna, jeśli nie - BŁĄD\n",
    "        assert dataset_len_img == dataset_len_labels, \"Ilośc obrazów jest niezgodna z ilością etykiet!\"\n",
    "        return dataset_len_img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples(test_model, \n",
    "                      number_of_exaples_to_generate, \n",
    "                      generator, \n",
    "                      exaples_dir):\n",
    "    \"\"\" \n",
    "    Opis:\n",
    "    ---\n",
    "    Funkcja generuje pliki png przedstawiajace obraz oryginalny, \n",
    "    przewidywania sieci oraz etykietę (na jednym obrazie).\n",
    "    \n",
    "    Argumenty:\n",
    "    ---\n",
    "        test_model (keras.engine.training.Model):   model sieci neuronowej z załadowanymi wagami\n",
    "        \n",
    "        number_of_exaples_to_generate (string):     ilość generowanych przykładw (plików png) \n",
    "                                                    w którym zapisane sa obrazy\n",
    "        \n",
    "        generator (generator):                      generator próbek (obraz + etykieta)\n",
    "                                                                  \n",
    "        exaples_dir (string):                       nazwa katalogu wyjściowego\n",
    "    \n",
    "    Return:\n",
    "    ---\n",
    "        None\n",
    "    \"\"\"\n",
    "    plt.ioff()\n",
    "    # dla każdej próbki uczącej\n",
    "    for number in range(number_of_exaples_to_generate):\n",
    "        img, label = generator.__next__()                             # pobranie obrazu i etykiety\n",
    "        y_pred = test_model.predict(x = img)                          # dokonanie przewidywań dla obrazu\n",
    "        y_pred = y_pred[0].reshape(image_height, image_width, 2)      # przekształcenie z kodowania gorąco-jedynkowego \n",
    "                                                                      # (przewidywania)  \n",
    "        label = label.reshape(image_height, image_width, 2)           # przekształcenie z kodowania gorąco-jedynkowego\n",
    "                                                                      # (etykieta)\n",
    "        img_org = img.copy()\n",
    "\n",
    "        # jeśli prawdopodobieństwo przynależności piksela do klasy droga > 50% \n",
    "        # to oznacz piksel na zielono\n",
    "        for i in range(image_height):\n",
    "            for j in range(image_width):\n",
    "                if y_pred[i,j,0] > 0.2 and y_pred[i,j,0] < 0.5:\n",
    "                    img[0,i,j,0] += 0\n",
    "                elif y_pred[i,j,0] > 0.5 and y_pred[i,j,0] < 0.9:\n",
    "                    img[0,i,j,1] = 250\n",
    "                elif y_pred[i,j,0] > 0.90:\n",
    "                    img[0,i,j,1] = 250\n",
    "        \n",
    "        # stworzenie obrazu przedstawiajacego obraz oryginalny, przewidywania, etykietę\n",
    "        fig = plt.figure(figsize=(14, 12), dpi = image_height)\n",
    "        fig.add_subplot(1, 3, 1)\n",
    "        plt.imshow(img_org[0,:,:,:].astype(np.uint8))\n",
    "        fig.add_subplot(1, 3, 2)\n",
    "        plt.imshow(img[0,:,:,:].astype(np.uint8))\n",
    "        fig.add_subplot(1, 3, 3)\n",
    "        plt.imshow(label[:,:,0].astype(np.uint8))\n",
    "\n",
    "        # zapis obrazu do pliku png\n",
    "        figure_name = exaples_dir + 'example_{}'.format(number + 1) \n",
    "        plt.savefig(figure_name)\n",
    "        plt.close(fig)\n",
    "        gc.collect()\n",
    "        clear_output()\n",
    "        print('Zapisanych: {}/{}'.format(number + 1, number_of_exaples_to_generate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predict_time(test_model,\n",
    "                           number_of_exaples_to_generate, \n",
    "                           generator):\n",
    "    \"\"\" \n",
    "    Opis:\n",
    "    ---\n",
    "    Funkcja dokonuje przewidywań sieci dla number_of_exaples_to_generate próbek\n",
    "    i wyznacza czas potrzebny do dokonania przewidywań dla pojedynczej prbki.\n",
    "    (jako średnia dla number_of_exaples_to_generate próbek)\n",
    "    \n",
    "    Argumenty:\n",
    "    ---\n",
    "        test_model (keras.engine.training.Model):   model sieci neuronowej z załadowanymi wagami\n",
    "        \n",
    "        number_of_exaples_to_generate (string):     ilość generowanych przykładw (plików png) \n",
    "                                                    w którym zapisane sa obrazy\n",
    "        \n",
    "        generator (generator):                      generator próbek (obraz + etykieta)\n",
    "                                                                \n",
    "    Return:\n",
    "    ---\n",
    "        None\n",
    "    \"\"\"\n",
    "    time_all = 0\n",
    "    # dla każdej prbki\n",
    "    for number in range(number_of_exaples_to_generate):\n",
    "        img = generator.__next__()                                 # pobranie zdjcia\n",
    "        start_time = time.time()                                   # rozpoczęcie odmierzania czasu\n",
    "        y_pred = test_model.predict(x = img)                       # dokonanie przewidywań\n",
    "        stop_time = time.time()                                    # zakończenie odmierzania czasu\n",
    "        pred_time = stop_time - start_time                         # wyznaczenie czasu przewidywań dla pojedynczej próbki\n",
    "        time_all += pred_time                                      # czas sumaryczny dla wszytskich próbek\n",
    "    time_for_single_example = time_all / number_of_exaples_to_generate  # średnia przewidywań\n",
    "    \n",
    "    print(\"Czas przewidywań dla pojedynczej próbki: {:.4f} s (średnia dla {} próbek).\"\\\n",
    "          .format(time_for_single_example, number_of_exaples_to_generate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16(model_input, weights = 'imagenet', weight_decay = 0.):\n",
    "    \"\"\" \n",
    "    Opis:\n",
    "    ---\n",
    "    Funkcja implementująca architekturę VGG16, bez ostatnich warstw w pełni połączonych.\n",
    "    \n",
    "    Argumenty:\n",
    "    ---\n",
    "        model_input (tensorflow.python.framework.ops.Tensor):   warstwa wejciowa (tensor)\n",
    "        \n",
    "        weights (string):                                       załadowanie wag imagenet\n",
    "                                \n",
    "        weight_decay (string):                                  wartosć współczynnik regularizacji\n",
    "    \n",
    "    Return:\n",
    "    ---\n",
    "        truple:                                                 krotka, ktrej elementy są typu\n",
    "                                                                tensorflow.python.framework.ops.Tensor\n",
    "                                                                (3,4,5 warstwa buforowa modelu)\n",
    "    \"\"\"\n",
    "    # pierwsza warstwa konwolucyjna\n",
    "    x = Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block1_conv1',\n",
    "               data_format = 'channels_last', kernel_regularizer = l2(weight_decay))(model_input)   \n",
    "    \n",
    "    x = Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block1_conv2',\n",
    "               data_format = 'channels_last', kernel_regularizer = l2(weight_decay))(x)   \n",
    "    \n",
    "    # pierwsza warstwa buforowa\n",
    "    x = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same', \n",
    "               name = 'block1_pool', data_format = 'channels_last')(x)\n",
    "\n",
    "    \n",
    "    # druga warstwa konwolucyjna\n",
    "    x = Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block2_conv1',\n",
    "               data_format = 'channels_last', kernel_regularizer = l2(weight_decay))(x)   \n",
    "    \n",
    "    x = Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block2_conv2',\n",
    "               data_format = 'channels_last', kernel_regularizer = l2(weight_decay))(x)  \n",
    "    \n",
    "    # druga warstwa buforowa\n",
    "    x = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same', \n",
    "               name = 'block2_pool', data_format = 'channels_last')(x)\n",
    "\n",
    "    \n",
    "    # trzecia warstwa konwolucyjna\n",
    "    x = Conv2D(filters = 256, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block3_conv1',\n",
    "               data_format = 'channels_last', kernel_regularizer = l2(weight_decay))(x)  \n",
    "    \n",
    "    x = Conv2D(filters = 256, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block3_conv2',\n",
    "               data_format = 'channels_last', kernel_regularizer = l2(weight_decay))(x)  \n",
    "    \n",
    "    x = Conv2D(filters = 256, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block3_conv3',\n",
    "               data_format = 'channels_last', kernel_regularizer = l2(weight_decay))(x)  \n",
    "    \n",
    "    # trzecia warstwa buforowa\n",
    "    x = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same', \n",
    "               name = 'block3_pool', data_format = 'channels_last')(x)\n",
    "    \n",
    "    # pierwszy element zwracanej krotki = trzecia warstwa buforowa\n",
    "    pool3 = x\n",
    "    \n",
    "    \n",
    "    # czwarta warstwa konwolucyjna\n",
    "    x = Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block4_conv1',\n",
    "               data_format = 'channels_last', kernel_regularizer = l2(weight_decay))(x)  \n",
    "    \n",
    "    x = Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block4_conv2',\n",
    "               data_format = 'channels_last', kernel_regularizer = l2(weight_decay))(x) \n",
    "    \n",
    "    x = Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block4_conv3',\n",
    "               data_format = 'channels_last', kernel_regularizer = l2(weight_decay))(x) \n",
    "    \n",
    "    # czwarta warstwa buforowa\n",
    "    x = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same', \n",
    "               name = 'block4_pool', data_format = 'channels_last')(x)\n",
    "\n",
    "    # drugi element zwracanej krotki = czwarta warstwa buforowa\n",
    "    pool4 = x\n",
    "    \n",
    "    \n",
    "    # piąta warstwa konwolucyjna\n",
    "    x = Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block5_conv1',\n",
    "               data_format = 'channels_last', kernel_regularizer=l2(weight_decay))(x) \n",
    "    \n",
    "    x = Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block5_conv2',\n",
    "               data_format = 'channels_last', kernel_regularizer=l2(weight_decay))(x) \n",
    "    \n",
    "    x = Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block5_conv3',\n",
    "               data_format = 'channels_last', kernel_regularizer=l2(weight_decay))(x) \n",
    "    \n",
    "    # trzeci element zwracanej krotki = piąta warstwa buforowa\n",
    "    x = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same', \n",
    "               name = 'block5_pool', data_format = 'channels_last')(x)\n",
    "    \n",
    "    \n",
    "    # załadowanie wag ImageNet\n",
    "    model_temp = Model(inputs = model_input, outputs = x)\n",
    "    if weights is not None:\n",
    "        model_temp.load_weights(vgg16_weights_file)\n",
    "        \n",
    "    layers = (pool3, pool4, x)\n",
    "\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCN8(model_out, pool3, pool4, pool5, classes, dropout = 0.5, weight_decay = 0.):  \n",
    "    \"\"\" \n",
    "    Opis:\n",
    "    ---\n",
    "    Funkcja implementująca architekturę FCN8.\n",
    "    \n",
    "    Argumenty:\n",
    "    ---\n",
    "        model_out (truple):                              rozmiat tensora reprezentującego warstwę wyjściową\n",
    "        \n",
    "        pool3 (tensorflow.python.framework.ops.Tensor):  trzecia warstwa buforowa modelu VGG16\n",
    "                     \n",
    "        pool4 (tensorflow.python.framework.ops.Tensor):  czwarta warstwa buforowa modelu VGG16\n",
    "        \n",
    "        pool5 (tensorflow.python.framework.ops.Tensor):  piąta warstwa buforowa modelu VGG16\n",
    "                     \n",
    "        classes (int):                                   liczba klas w zbiorze danych\n",
    "        \n",
    "        dropout (float):                                 wartość współczynnika dropout\n",
    "        \n",
    "        weight_decay (string):                           wartosć współczynnik regularizacji\n",
    "    \n",
    "    Return:\n",
    "    ---\n",
    "        tensorflow.python.framework.ops.Tensor:          warstwa wyjściowa modelu\n",
    "                                                                \n",
    "    \"\"\"\n",
    "    # szósta warstwa konwolucyjna\n",
    "    x = Conv2D(filters = 4096, kernel_size = (7, 7), activation = 'relu', padding = 'same', \n",
    "                 name = 'block6_conv1', data_format = 'channels_last')(pool5)\n",
    "    # warstwa dropout\n",
    "    x = Dropout(rate = dropout)(x)\n",
    "    \n",
    "    # siódma warstwa konwolucyjna\n",
    "    x = Conv2D(filters = 4096, kernel_size = (1, 1), activation = 'relu', padding = 'same', \n",
    "               name = 'block6_conv2', data_format = 'channels_last')(x)\n",
    "    # warstwa dropout\n",
    "    x = Dropout(rate = dropout)(x)\n",
    "\n",
    "    # wagi dla przewidywań \n",
    "    weight_pool5, weight_pool4, weight_pool3 = [1, 1e-2, 1e-4]\n",
    "    \n",
    "    # ----------------------\n",
    "    \n",
    "    # nadanie wagi dla przewidywań (związanych z warstwą pool5) \n",
    "    x = Lambda(lambda xx: xx * weight_pool5, name = 'weight_pool5')(x)\n",
    "    \n",
    "    # warstwa konwolucyjna (związana z warstwą pool5)\n",
    "    x = Conv2D(filters = classes, kernel_size = (1, 1), padding = 'valid', \n",
    "               kernel_initializer = 'he_normal', \n",
    "               name = 'score_feat1', data_format = 'channels_last', \n",
    "               activation='linear', kernel_regularizer = l2(weight_decay))(x)\n",
    "    \n",
    "    # warstwa dekonwolucyjna (związana z warstwą pool5)\n",
    "    y = Conv2DTranspose(filters = classes, kernel_size = (4, 4), strides = (2, 2), use_bias = False, \n",
    "                padding = 'valid', name = 'upscore_feat1', data_format = 'channels_last')(x)\n",
    "    \n",
    "    # ----------------------\n",
    "    \n",
    "    # nadanie wagi dla przewidywań (związanych z warstwą pool4) \n",
    "    pool4 = Lambda(lambda xx: xx * weight_pool4, name='weight_pool4')(pool4)\n",
    "    \n",
    "    # warstwa konwolucyjna (związana z warstwą pool4)\n",
    "    pool4 = Conv2D(filters = classes, kernel_size = (1, 1), padding = 'valid', \n",
    "                   kernel_initializer = 'he_normal', \n",
    "                   name = 'score_feat2', data_format = 'channels_last', \n",
    "                   activation='linear', kernel_regularizer = l2(weight_decay))(pool4)\n",
    "    \n",
    "    # dopasowanie wymiarów tensorów (związanego z warstwą dekonwolucyjną, związaną z warstwą pool5 \n",
    "    # i konwolucyjną związaną z warstwą pool4)\n",
    "    y = CroppingLike2D(target_shape = K.int_shape(pool4), data_format = 'channels_last', \n",
    "                       offset='centered', name = 'crop_feat2')(y)\n",
    "    \n",
    "    # dodanie przewidywań\n",
    "    y = Add()([y, pool4])\n",
    "    \n",
    "    # warstwa dekonwolucyjna\n",
    "    y = Conv2DTranspose(filters = classes, kernel_size = (4, 4), strides = (2, 2), use_bias = False, \n",
    "                padding = 'valid', name = 'upscore_feat2', data_format = 'channels_last')(y)\n",
    "    \n",
    "    # ----------------------\n",
    "    \n",
    "    # nadanie wagi dla przewidywań (związanych z warstwą pool3) \n",
    "    pool3 = Lambda(lambda xx: xx * weight_pool3, name='weight_pool3')(pool3)\n",
    "    \n",
    "    # warstwa konwolucyjna (związana z warstwą pool3)\n",
    "    pool3 = Conv2D(filters = classes, kernel_size = (1, 1), padding='valid' , \n",
    "                   kernel_initializer = 'he_normal', \n",
    "                   name = 'score_feat3', data_format = 'channels_last',\n",
    "                   activation='linear', kernel_regularizer = l2(weight_decay))(pool3)\n",
    "   \n",
    "    # dopasowanie wymiarów tensorów \n",
    "    y = CroppingLike2D(target_shape = K.int_shape(pool3), data_format = 'channels_last',\n",
    "                       offset='centered', name = 'crop_feat3')(y)\n",
    "    \n",
    "    # dodanie przewidywań\n",
    "    y = add([y, pool3])\n",
    "    \n",
    "    # warstwa dekonwolucyjna\n",
    "    y = Conv2DTranspose(filters = classes ,kernel_size = (16,16), strides = (8,8), use_bias = False, \n",
    "                padding = 'valid', name = 'upscore_feat3', data_format = 'channels_last')(y)\n",
    "    \n",
    "    # dopasowanie wymiaru tensora przewidywań do wymaganych przewidywań (podanych jako parametr)\n",
    "    outputs = CroppingLike2D(target_shape = model_out, data_format = 'channels_last', name = 'score')(y)  \n",
    "    \n",
    "    # ----------------------\n",
    "    \n",
    "    # kodowanie gorąco-jedynkowe\n",
    "    outputs = Reshape((image_height*image_width, classes), \n",
    "                       input_shape = (image_height,image_width,classes))(outputs)\n",
    "\n",
    "    # funkcja softmax\n",
    "    scores = Activation('softmax', name='segmentation')(outputs)\n",
    "        \n",
    "    return scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przykład"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uczenie = \"seg_park_tr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pliki wejściowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_dir = \"../../../Tools/\"\n",
    "\n",
    "# pliki hdf5\n",
    "hdf5_filename_train = tools_dir + 'hdf5/park_train_200_300.hdf5'\n",
    "hdf5_filename_eval = tools_dir + 'hdf5/park_eval_200_300.hdf5'\n",
    "hdf5_filename_test = tools_dir + 'hdf5/park_test_200_300.hdf5'\n",
    "\n",
    "# plik h5 z wagami ImageNet\n",
    "vgg16_weights_file = tools_dir + 'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pliki wyjściowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stworzenie katalogu, w którym zapisane zostaną pliki związane z procesem uczenia\n",
    "curr_dir =  os.getcwd()\n",
    "out_files_path = curr_dir + '/' + \"uczenie_out/\"\n",
    "now = datetime.datetime.now()\n",
    "if not os.path.exists(out_files_path):\n",
    "    os.makedirs(out_files_path)\n",
    "out_files_path += str(now.day) + '-' + str(now.month) + '-' + str(now.year)\n",
    "\n",
    "# stworzenie katalogu, w którym zapisany zostanie plik wag nauczonego modelu\n",
    "out_weights_dir = out_files_path + '/' + \"weights/\"\n",
    "if not os.path.exists(out_weights_dir):\n",
    "    os.makedirs(out_weights_dir)\n",
    "output_weights_file = out_weights_dir + uczenie + \"_\" + str(now.hour) + '-' + str(now.minute) + \".h5\" \n",
    "\n",
    "# stworzenie katalogu, w którym zapisany zostanie plik csv, związany z procesem cuzenia\n",
    "out_csv_dir = out_files_path + '/' + \"csv/\"    \n",
    "if not os.path.exists(out_csv_dir):\n",
    "    os.makedirs(out_csv_dir)  \n",
    "output_csv_file = out_csv_dir + uczenie + \"_\" +  str(now.hour) + '-' + str(now.minute) + \".csv\"      \n",
    "\n",
    "# stworzenie katalogu, w którym zapisany zostanie plik log, związany z procesem cuzenia\n",
    "out_log_dir = out_files_path + '/' + \"log/\"    \n",
    "if not os.path.exists(out_log_dir):\n",
    "    os.makedirs(out_log_dir)  \n",
    "output_log_file = out_log_dir + uczenie + \"_\" +  str(now.hour) + '-' + str(now.minute) + \".log\" \n",
    "\n",
    "with open(out_files_path + \"/README.txt\", 'w', encoding='utf-8') as file:\n",
    "    file.write(\"\"\"Katalogi generowane automatycznie. Zostaną uzupełnione plikami tylko jeśli\n",
    "komórki związane z procesem uczenia zostaną odkomentowane.\"\"\")\n",
    "\n",
    "learning_start = now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Podstawowe parametry procesu uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 200\n",
    "image_width = 300\n",
    "batch_size = 2\n",
    "img_depth = 3\n",
    "label_depth = 1\n",
    "epochs = 1                                                    # domyślnie tylko 1 epoka! \n",
    "img_shape = (image_height, image_width, img_depth)\n",
    "new_num_classes = 2\n",
    "out_size = (None, image_height, image_width, new_num_classes)\n",
    "optimizer = \"sgd\"\n",
    "LR = 0.001 \n",
    "DECAY = 0.0005 \n",
    "MOMENTUM = 0.9\n",
    "LOSS = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Przykładowe próbki  zbioru uczącego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_img_batch(hdf5_filename_train, \n",
    "                  \"imgs\", \n",
    "                  \"labels\", \n",
    "                  batch_size = 2,\n",
    "                  one_hot = True,\n",
    "                  class_index = 0)\n",
    "                \n",
    "train_len = number_of_examples_in_dataset(hdf5_filename_train, \"imgs\", \"labels\")                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Przykładowe próbki  zbioru walidacyjnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img_batch(hdf5_filename_eval, \n",
    "                  \"imgs\", \n",
    "                  \"labels\", \n",
    "                  batch_size = 2, \n",
    "                  one_hot = True,\n",
    "                  class_index = 0)\n",
    "\n",
    "eval_len = number_of_examples_in_dataset(hdf5_filename_eval, \"imgs\", \"labels\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Przykładowe próbki  zbioru testowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img_batch(hdf5_filename_test, \n",
    "                  \"imgs\", \n",
    "                  \"labels\", \n",
    "                  batch_size = 2, \n",
    "                  one_hot = True,\n",
    "                  class_index = 0)\n",
    "\n",
    "test_len = number_of_examples_in_dataset(hdf5_filename_test, \"imgs\", \"labels\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sprawdzenie poprawności działania funkcji batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = batch_generator(hdf5_filename_train, \n",
    "                    \"imgs\", \n",
    "                    \"labels\", \n",
    "                    batch_size = batch_size, \n",
    "                    one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img, label) = G.__next__()\n",
    "label = label[0,:,:].reshape((image_height, image_width, new_num_classes))\n",
    "fig=plt.figure()\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.imshow(img[0,:,:,:].astype(np.uint8))\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(label[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Należy odkomentować uczenie badź testowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uczenie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stworzenie modelu do uczenia"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# warstwa wejciowa\n",
    "train_model_input = Input(shape = img_shape)\n",
    "\n",
    "# implementacja architektury VGG16\n",
    "pool3, pool4, pool5 = VGG16(train_model_input, weight_decay = 1e-3) \n",
    "\n",
    "# implementacja architektury FCN8\n",
    "train_model_output = FCN8(out_size, pool3, pool4, pool5, new_num_classes, weight_decay = 1e-3)\n",
    "\n",
    "# stworzenie modelu całościowego\n",
    "train_model = Model(inputs = train_model_input, outputs = [train_model_output])\n",
    "\n",
    "# wyznaczenie warstw podlegających/niepodlegających procesowi uczenia\n",
    "for layer in train_model.layers:\n",
    "    config = layer.get_config()\n",
    "    if config['name'] != 'block2_pool':\n",
    "        layer.trainable = False\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# wyświetlenie podsumowania modelu i zapis do pliku\n",
    "train_model.summary()\n",
    "print_layer_trainable(train_model)\n",
    "plot_model( train_model, show_shapes = True , to_file=out_files_path + '/model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kompilacja modelu"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# metoda stochastycznego spadku wzdłóż gradientu\n",
    "sgd = optimizers.SGD(lr = LR, \n",
    "                     decay = DECAY, \n",
    "                     momentum = MOMENTUM)\n",
    "\n",
    "train_model.compile(optimizer = sgd,\n",
    "                    loss = LOSS,\n",
    "                    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcje wywoływane w trakcie procesu uczenia"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# zapis wag do pliku jeśli dla danej epoki nastąpiła poprawa dokładności modelu\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath = output_weights_file,\n",
    "    verbose = 1,\n",
    "    save_best_only = True)\n",
    "\n",
    "# redukcja współczynnika uczenia w trakcie procesu uczenia\n",
    "lr_reducer = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                               factor = np.sqrt(0.1),\n",
    "                               cooldown = 0,\n",
    "                               patience = 10, \n",
    "                               min_lr = 1e-12)\n",
    "\n",
    "# przerwanie uczenia jeśli brak poprawy\n",
    "early_stopper = EarlyStopping(monitor = 'val_loss',\n",
    "                              min_delta = 0.001,\n",
    "                              patience = 50)\n",
    "# zapis do pliku CSV\n",
    "csv_logger = CSVLogger(output_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stworzenie generatorów próbek"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# stworzenie generatora dla zbioru treningowego\n",
    "G = batch_generator(hdf5_filename_train, \n",
    "                  \"imgs\", \n",
    "                  \"labels\", \n",
    "                  batch_size = batch_size, \n",
    "                  one_hot = True)\n",
    "\n",
    "# stworzenie generatora dla zbioru walidacyjnego\n",
    "G2 = batch_generator(hdf5_filename_eval, \n",
    "                     \"imgs\", \n",
    "                     \"labels\", \n",
    "                      batch_size = batch_size, \n",
    "                      one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proces uczenia"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "history = train_model.fit_generator(generator = G,\n",
    "                                    steps_per_epoch = int(np.ceil(train_len / float(batch_size))),\n",
    "                                    epochs = epochs,\n",
    "                                    verbose = 1,\n",
    "                                    validation_data = G2,\n",
    "                                    validation_steps = int(np.ceil(eval_len / float(batch_size))),\n",
    "                                    callbacks=[lr_reducer, csv_logger, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zapis histori uczenia do pliku, po zakończeniu uczenia"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "learning_stop = datetime.datetime.now()\n",
    "with open(output_log_file, 'w') as file:\n",
    "    file.write(\"Raport treningowy\\n\")\n",
    "    file.write(\"Czas rozpoczecia uczenia: {}\\n\".format(learning_start))\n",
    "    file.write(\"Czas zakonczenia uczenia: {}\\n\".format(learning_stop))\n",
    "    file.write(\"Parametry treningu\\n\")\n",
    "    file.write(\"Wysokość obrazu wyjściowego: {}\\n\".format(image_height))\n",
    "    file.write(\"Szerokość obrazu wyjściowego: {}\\n\".format(image_width))\n",
    "    file.write(\"Liczba klas etykiety: {}\\n\".format(label_depth))\n",
    "    file.write(\"Wielkość mini-paczki obrazów (batch size): {}\\n\".format(batch_size))\n",
    "    file.write(\"Liczba epok uczenia: {}\\n\".format(epochs))\n",
    "    file.write(\"Liczba klas szukanych w obrazie: {}\\n\".format(new_num_classes))\n",
    "    file.write(\"Typ optymalizacji: {}\\n\".format(optimizer))\n",
    "    file.write(\"Learning rate: {}\\n\".format(LR))\n",
    "    file.write(\"Decay: {}\\n\".format(DECAY))\n",
    "    file.write(\"Momentum: {}\\n\".format(MOMENTUM))\n",
    "    file.write(\"Loss: {}\\n\".format(LOSS))\n",
    "    file.write(\"Nazwa powiązanego pliku wag: {}\\n\".format(output_weights_file))\n",
    "    file.write(\"Nazwa powiązanego pliku csv: {}\\n\".format(output_csv_file))\n",
    "    file.write(\"Ilość obrazów w zbiorze treningowym: {}\\n\".format(train_len))\n",
    "    file.write(\"Ilość obrazów w zbiorze walidacyjnym: {}\\n\".format(eval_len))\n",
    "    file.write(\"Ilość obrazów w zbiorze testowym: {}\\n\".format(test_len))\n",
    "    file.write(\"Dokładnoć dla zbioru treningowego: {}\\n\".format(history.history['acc']))\n",
    "    file.write(\"Wartośc funkcji straty dla zbioru treningowego: {}\\n\".format(history.history['loss']))\n",
    "    file.write(\"Dokładnoć dla zbioru walidacyjnego: {}\\n\".format(history.history['val_acc']))\n",
    "    file.write(\"Wartośc funkcji straty dla zbioru walidacyjnego: {}\\n\".format(history.history['val_loss']))\n",
    "    file.write(\"Model summary: \\n\")\n",
    "    train_model.summary(print_fn = lambda x: file.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testowanie modelu\n",
    "Przed uruchomieniem konieczne jest odkomentowanie poniższych komórek, zakomentowanie tych związanych z procesem uczenia i ponowne uruchomienie notatnika (Kernel > Restart and run all (zwykle x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stworzenie modelu testowego i wczytanie wag wyznaczonych w procesie uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ścieżka do pliku zawierającego nauczone wagi\n",
    "model_weights_file = \"seg_park_ft_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_inp = Input(shape = img_shape, dtype = 'float32')\n",
    "pool3, pool4, pool5 = VGG16(x_test_inp, weights = \"None\")\n",
    "test_model_output = FCN8(out_size, pool3, pool4, pool5, new_num_classes)\n",
    "test_model = Model(inputs = x_test_inp, outputs = test_model_output)\n",
    "test_model.load_weights(model_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.001, \n",
    "                     decay = 0.0005, \n",
    "                     momentum = 0.9)\n",
    "                     \n",
    "test_model.compile(optimizer = sgd,\n",
    "                   loss = 'categorical_crossentropy',\n",
    "                   metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G3 = batch_generator(hdf5_filename_test, \n",
    "                     \"imgs\", \n",
    "                     \"labels\", \n",
    "                     batch_size = 1, \n",
    "                     one_hot = True,\n",
    "                     shuffle_batch = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sprawdzenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_model.evaluate_generator(G3, steps = 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(test_model.metrics_names, result):\n",
    "    print(name, value)\n",
    "print(\"{0}: {1:.2%}\".format(test_model.metrics_names[1], result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wizualizacja wynikow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dokonanie przewidywań dla obrazów i zapis wyniku w postaci plików png \n",
    "# przedstawiających obraz oryginalny, przewidywania sieci oraz etykietę. \n",
    "\n",
    "# ilość stworzonych plików png\n",
    "number_of_exaples_to_generate = 5\n",
    "\n",
    "# katalog, w kótrym powstaną pliki wynikowe\n",
    "exaples_dir = os.getcwd() + \"/examples/\"\n",
    "if not os.path.exists(exaples_dir):\n",
    "    os.makedirs(exaples_dir)\n",
    "\n",
    "# generator testowy \n",
    "G4 = batch_generator(hdf5_filename_test, \n",
    "                     \"imgs\", \n",
    "                     \"labels\", \n",
    "                     batch_size = 1, \n",
    "                     one_hot = True,\n",
    "                     shuffle_batch = False)    \n",
    "\n",
    "generate_examples(test_model, number_of_exaples_to_generate, G4, exaples_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyznaczenie czasu potrzebnego na dokonanie przewidywań dla pojedynczej próbki \n",
    "# (jako średnia dla number_of_exaples_to_generate)\n",
    "\n",
    "#ilość próbek, dla których wyznaczona zostanie średnia\n",
    "number_of_exaples_to_generate = 100\n",
    "\n",
    "# generator testowy \n",
    "G5 = batch_generator_test(hdf5_filename_test, \n",
    "                  \"imgs\", \n",
    "                  batch_size = 1)\n",
    "\n",
    "calculate_predict_time(test_model, number_of_exaples_to_generate, G5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
